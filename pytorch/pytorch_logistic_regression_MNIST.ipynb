{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters initialization\n",
    "\n",
    "IMAGE_SIZE = 28*28\n",
    "NUM_CLASSES = 10\n",
    "MAX_EPOCH = 5\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size,num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        # 1 input image : 28*28 , output is 10 classes\n",
    "        self.linear = nn.Linear(in_features=IMAGE_SIZE, out_features=NUM_CLASSES,bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download MNIST dataset\n",
    "ROOT = \"data/\"\n",
    "\n",
    "#transforms.ToTensor() transforms the PIL.Image.Image format to pytorch Tensor \n",
    "\n",
    "train_MINST = MNIST(ROOT+\"MNIST\", train=True, download=True,transform=transforms.ToTensor())\n",
    "test_MINST = MNIST(ROOT+\"MNIST\", train=False, download=True,transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_MINST,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_MINST,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "#Before iterating all the training set, verfiy the dimensions of the training and target tensors of a random example\n",
    "(images, labels) = list(train_data_loader)[0]\n",
    "# images shape now is [BATCH_SIZE, 1, 28, 28], it should be reshaped ot [BATCH_SIZE,IMAGE_SIZE]\n",
    "images = images.reshape(-1,IMAGE_SIZE)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "assert images.shape[0] == BATCH_SIZE\n",
    "assert images.shape[1] == IMAGE_SIZE\n",
    "assert labels.shape[0] == BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How PyTorch calculates Cross Entropy\n",
    "\n",
    "Pytorch calculates the softmax of the output first before calculating the cross entropy.\n",
    "\n",
    "For example, assume we have four classes and the output of the model is something like [0,0,0,1] and the actual target is [3]. Calculating the cross entropy directly should equal to zero (1*log(1)). \n",
    "\n",
    "However, PyTorch converts the outputs to probabilities that sums to 1 using softmax: \n",
    "softmax([0,0,0,1]) =  [0.1749,0.1749,0.1749,0.4754]\n",
    "Then, apply the cross entropy formula -log(0.4754) = 0.7437\n",
    "\n",
    "Reference: https://stackoverflow.com/questions/49390842/cross-entropy-in-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7437)\n"
     ]
    }
   ],
   "source": [
    "output = Variable(torch.FloatTensor([0,0,0,1])).view(1, -1)\n",
    "target = Variable(torch.LongTensor([3]))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "del loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple logistic regression model\n",
    "$$y_{m*c} = x_{m*n} * w_{n*c} + b_{m*c}$$\n",
    "where $m$ is the number of examples (i.e. the number of the training images), $n$ is the number of features (i.e. the image size) and $c$ is the number of the classes\n",
    "\n",
    "Note that $b$ have the same values that are broadcasted to all the examples $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.023\n",
      "[1,   101] loss: 2.057\n",
      "[1,   201] loss: 1.687\n",
      "[1,   301] loss: 1.445\n",
      "[1,   401] loss: 1.264\n",
      "[1,   501] loss: 1.137\n",
      "[2,     1] loss: 0.009\n",
      "[2,   101] loss: 0.956\n",
      "[2,   201] loss: 0.909\n",
      "[2,   301] loss: 0.852\n",
      "[2,   401] loss: 0.828\n",
      "[2,   501] loss: 0.784\n",
      "[3,     1] loss: 0.007\n",
      "[3,   101] loss: 0.735\n",
      "[3,   201] loss: 0.706\n",
      "[3,   301] loss: 0.691\n",
      "[3,   401] loss: 0.682\n",
      "[3,   501] loss: 0.646\n",
      "[4,     1] loss: 0.008\n",
      "[4,   101] loss: 0.619\n",
      "[4,   201] loss: 0.613\n",
      "[4,   301] loss: 0.616\n",
      "[4,   401] loss: 0.599\n",
      "[4,   501] loss: 0.577\n",
      "[5,     1] loss: 0.006\n",
      "[5,   101] loss: 0.586\n",
      "[5,   201] loss: 0.552\n",
      "[5,   301] loss: 0.557\n",
      "[5,   401] loss: 0.543\n",
      "[5,   501] loss: 0.549\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(IMAGE_SIZE, NUM_CLASSES)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(lr_model.parameters(), lr=LEARNING_RATE)  \n",
    "\n",
    "for epoch in range(0,MAX_EPOCH):\n",
    "    \n",
    "    running_loss = 0\n",
    "    #train_data_loader is already partitioned to multiple batches, each batch with size = LENGTH(TRAINING_SET)/BATCH_SIZE\n",
    "    for batch_index, (images, labels) in enumerate(train_data_loader):\n",
    "        images = Variable(images.reshape(-1, 28*28),requires_grad=True)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        #reset the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #calculate predictions (y^)\n",
    "        predictions = lr_model(images)\n",
    "        \n",
    "        #calculate Cross Entropy loss between labels(y) and predictions(y^)\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        #Backward propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch_index % 100 == 0:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, batch_index + 1, running_loss / 100))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the learned weights vector w\n",
    "w = list(lr_model.parameters())[0]\n",
    "\n",
    "assert w.shape[0] == NUM_CLASSES\n",
    "assert w.shape[1] == IMAGE_SIZE\n",
    "\n",
    "# get the learned bias vector b\n",
    "b = list(lr_model.parameters())[1]\n",
    "\n",
    "assert b.shape[0] == NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct classified test images: 87 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model accuracy\n",
    "correct_instances = 0\n",
    "total_test_examples = 0\n",
    "for images, labels in test_data_loader:\n",
    "    images = Variable(images.reshape(-1, 28*28))\n",
    "    predictions_output = lr_model(images)\n",
    "    _, predicted_classes = torch.max(predictions_output.data, 1)\n",
    "    total_test_examples = total_test_examples + len(images)\n",
    "    correct_instances = correct_instances + (predicted_classes == labels).sum()\n",
    "\n",
    "print('Number of correct classified test images: %d %%' % (100 * correct_instances / total_test_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the model predictions\n",
    "Reference: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#sphx-glr-beginner-transfer-learning-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(lr_model,dataloaders, num_images=6):\n",
    "    was_training = lr_model.training\n",
    "    lr_model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders):\n",
    "            inputs = inputs.reshape(-1,IMAGE_SIZE)\n",
    "            outputs = lr_model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(preds[j]))\n",
    "                plt.imshow(inputs.reshape(-1,28,28).data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    lr_model.train(mode=was_training)\n",
    "                    return\n",
    "        lr_model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAEICAYAAABicSBTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VcX9//HXJ4GEVTbBhX0Vd9AqIi7YarUqtsWFVm1Ff1SwqK1Wy9dqpVa02lKpShWXikvVilurVqxSa6sCiiAugAjIFtaAQQSMkGR+f8y5597sCSSTm+T9fDzuI+fOzJkz9+Zk8jnbjDnnEBEJJaOuGyAijYs6HREJSp2OiASlTkdEglKnIyJBqdMRkaDqdadjZg+b2YRo+XgzWxxou87M+oTYljRODXnfrtedTirn3JvOuQMqK2dmI83srRBtirbX3syeMrPNZrbJzB43s71CbV/qv3Tdt1O2297Mcqu67bTpdMysSV23oZZMANoBPYHewD7Ab+qyQRJWA963E24HFlW1cK12Oma2wsyuM7OFZpZnZlPNrFmUN9TMcsxsnJmtB6ZG6Wea2Xwz22JmM83ssJT6BprZPDP70syeApql5A01s5yU913N7LmoB95sZpPN7EBgCjDYzLaZ2ZaobLaZTTSzVWa2wcymmFnzlLquNbN1ZrbWzC6p5tfQE/i7c26rc+4L4Hng4Op+l5JetG/H6x8LHJL4jFXinKu1F7AC+BjoCrQH3gYmRHlDgQJ8L5kNNAcGAhuBQUAmcFFURzaQBawErgKaAucAu0rUlxMtZwIfAJOAlvhf4HFR3kjgrRLtnAS8ELWxNfAi8Lso7zRgQ/TFtgSeABzQJ8o/H/iwgu/gTOBlfLTTDngd+Hltfu961f5L+3bclnnAkWVtu9z1AvxixqS8Px1YlvJF7gSapeTfC9xcoo7FwInACcBawFLyZpbzixkM5AJNymhTsS8HMGA70DslbTCwPFp+CLgtJa9f6i+mCt/B/sAMoCh6vQZk1fUfjV579tK+7cB3kveWte2KXiGONVenLK/E/xEm5Drn8lPedwcuMrMrUtKyonUcsMZFnzClvrJ0BVY65wqq0L6OQAtgrpkl0gzfixNte24VtlmeacCHwHejeicCfwXOq2Y9kn4a7b5tZvsDV+KjnGoJ0el0TVnuhu/RE0o+4r4auMU5d0vJSszsRKCzmVnKL6cbsKyMba4GuplZkzJ+OSW3uQn4CjjYObemjLrWlfEZqmMAMNY5tz36HFOA4FcYpFY05n37aGA/YGHUoTUHmkfnsDo75wrLWzHE1auxZtbFzNoD1wNPVVD2AWCMmQ0yr6WZnWFmrYFZ+OPkK82sqZkNx3/wsryL/0Jvi+poZmZDorwNQBczywJwzhVF251kZp0AzKyzmZ0alZ8GjDSzg8ysBTC+mp9/DjDKzJpHJ/AuxUc+Uv815n17OtAD/091AHAj8D4woKIOB8J0Ok8ArwKf4XvuCeUVdM69B/wEmAzkAUvxx4o453YCw6P3nwMjgOfKqacQGAb0AVYBOVF58CdyFwDrzWxTlDYu2tZsM9uKPwdzQFTXdOBP0XpLo58xM7vAzBZU8Pkvwf9ycoA1QC/8SUSp/xrtvu2c+9o5tz7xAr4AdkXLFbLih5E1y8xWAKOcczNqbSMidUD79u5Lm5sDRaRxUKcjIkHV6uGViEhJinREJKigD6KdknFuow6rXit62iovJfWN9uvq7deKdEQkKHU6IhKUOh0RCUqdjogEpU5HRIJSpyMiQanTEZGg1OmISFDqdEQkKHU6IhJUg52PJ3Ov5Hx2n/zuQACyOu4A4Pjun8V5w9q/D8AZLbYBcOCjYwHoed2sIO0UaWwU6YhIUOp0RCSohnN4leFn1Vh+ix/P+rfD/xZnndvqjWJFC0iOG33jxqMAOKPFPJ/Qc3stNlKkfNYk+ee4+pd+Pz76rI8A2Hh2awAK1qwtvWI9o0hHRIJqMJFO7mj/n2HRj/9cadkPdiaX/3PnYL9wy7zaaJZIpSw7G4DFdx4epy0dNhmAzUVfATCybTTNeFmzV1VDk87J+QA3fKc7AHs/4ufbc7t2lrlOTVOkIyJB1ftIp+j4gQD84Zr7Abgzrw8Ad791clxm6bApAHxr1GgAWs5Pzgb79XkazE/qVsHgg4HkfgqwrtDf3nHWrdcC0HFBzdzC0eX5vHh58j7TABg700dRhQs/rZFtVEaRjogEpU5HRIKq94dXqy73l7+HNtsFwKjX/GFV/2sXxWX6Flzmf05/B/CTRie0PzO7WH1tXm1ZW00VKdNn388qlXbKO36f7TalZg6rdnx/EACXdrw7Thvx8cUAtAt0WJWgSEdEgqr3kY5Z8dk/Th7o53tfvTMZz/S9/J1iZdzg5KXJGQdNBeDNfP9VdHrdX5MsQKR2ZfbtBcDDKSeQEzo90rxGtpFxuH/u8I93+EvwA7Lq/k9ekY6IBFX33d4eajmjFQD/PsKfm5nS5U0ALng9ecl861n+PE3h5s8BWD+u9E1Qo57zl9N7r9DT5RLGJ5d3AmBIdlGN153Ztg0A62/2dR+ZlVnj29hdinREJKh6H+nsfb+PTCZ+fD4AL9/tz+k83mNGXObF2X5snRse/LF/P/D3cd4v1g8FoO+v/bg6Nf8/R6Rs2fsXf7j4t5sOjZdbvr0EIOXR5MpltG4dL+f+dR8A5gx8stzym5d0AKAdS6qxlT2nSEdEglKnIyJB1fvDqwSb+QEAi4c0A+CYZ34Q580e6MfWGXbl5CilRZz35n1+PJ2983UCWerW2vy28XJhXl4FJYtLPKW+ZVqnOG32YX6fv32zv2Q+rsOiUuv1ev7r3WrnnlKkIyJBNZhIJ6EoPx+ADjelPN7w9/LLb+vmf+5di20SqQ27Tj4SgKJfbgbgrYOfjvMGzx8BQIvJPnoa92DpSKeuKNIRkaAaXKSTsOzcVqXSrlh7LAC/2fffcdrCi/1Ig8cs81PPtJ+qcztSN05r91G8/JcDvg1A4eKlxcqsGn9svPyv/+dv/Wif4f+M+z92VZzXe7wfCbNgcGvSjSIdEQlKnY6IBNXgDq++uPAYAD44/8447f82+LFElh3lTzJ/Z/Q1cd6MG/4IwClXvg3AvCf8073u67q5nCiNR/ab/tDn68F+TIOzW22N8266vSkA7Vv0AOCNQxJXQ+bHZbYV+T/fIx/xh1W9rk+eGig+9gJkWvrEF+nTEhFpFBpMpGMD/eDWQ656F4D/5CfnMl94xj7R0noA9r4v+R9h+Dk/BGDGQc8D8K1v+afNs1+eU6vtFdnnrpkADM78OQD/vvoPcd77Rz1erOzsfB+7/Hr59+K0XRP3BaDH9MovfhS69HmqUJGOiATVYCKdEx55D4ARbfzEYT++NnneptW62XXSJpGq2HeSj3i+u+YXcdq2zsXjgc6PLQYgY1Ny+qRsVlNdEz8/IF7O+nQdEH6UTEU6IhJUvY90Nv/ETwt8cVt/PHzsy1cD0G+aohupX1ql7LMlb22tzrg6Ffnvpr7JOtetraFaq0eRjogEpU5HRIKq94dX207ZBkDr6PmTbi9Vvk5i/BGAfm02ArAxmjs664tdNdxCkbqzbET6/Ykr0hGRoNKvG6ymFwb5icpGrRwGQLOX3q10nU8fODhe/mfnBwEYPD+aYvXt+WWuI1If7dtjc7H366d1j5c7ohPJItII1PtIZ+FO/4jD6i/9CGlte/qH6AqWr4zL5A87GoBVZ/pbyV8/cVKc90a+n5Ss7YTkuMkiDVXr1TV18X33KdIRkaDU6YhIUPX+8GrcvOEALDzuYQBWvOEvfW8pyorL9Gnqn8Jtk+HHyhn68YVxXtZ4f3hlsz6o9baKhOac1XUTSlGkIyJB1ftIp9fv/DOyI+72A1kXRT37x2v3K1V2/8f8TYHN//dJnFb05YpabqGIpFKkIyJB1ftIp2j+QgC+PL54ek9yy1+nNhskkob+ucM/t95y+RdxWl1dPFekIyJB1ftIR0TK1+Z0P1nfn+kXpSyuu8ZEFOmISFDqdEQkqHrd6Sxwc1jqPgYgz+Uy070SZLsz3DPscNuCbEsap4a8b9frTidVO+vIsXZapeXWuhXMcf8J0CJvg1vNHPc6r7vnMbM3gm1YGox03bd3uZ185GZjZpvNbJOZPW5me1W2njlXcgLSumFmTZxz1ZoNw8weBnKcczdUY52RwCjn3HHVa2GxOhzQ1zm3tAplTwbaA/2Bbzrnhu7udqV+asD79j1AH+AcwIBngQ+dc1dXtF6tRjpmtsLMrjOzhWaWZ2ZTzaxZlDfUzHLMbJyZrQemRulnmtl8M9tiZjPN7LCU+gaa2Twz+9LMngKapeQNNbOclPddzew5M8uNeuLJZnYgMAUYbGbbzGxLVDbbzCaa2Soz22BmU8yseUpd15rZOjNba2aXVOc7cM7NcM5NgzoaMUlqhfZtAHoCf3fObXXOfQE8DxxcyTpBDq8uAE4FegP9gNSee198FNAduNTMBgIPAaOBDsB9wAvRF5cF/B14LFrnaeDssjZoZpnAS8BKoAfQGfibc24RMAaY5Zxr5ZxrG61yW9S2AfieuzNwY1TXacA1wClAX+DkEts638w+3J0vRuq9xr5v/xk408zamVm7qM3TKyjvOedq7QWsAMakvD8dWBYtDwV2As1S8u8Fbi5Rx2LgROAEfLRgKXkzgQkp9eVEy4OBXKBJGW0aCbyV8t6A7UDvlLTBwPJo+SHgtpS8foAD+lTzuxgFvFGb37de4V7atx3A/sAM/E3+RcBrQFZl64W4OTB17tOVUUMTcp1z+SnvuwMXmdkVKWlZ0ToOWOOiT5tSX1m6Aitd1Y6jOwItgLlm8TAABmRGy/sDc6uwTWl8Gvu+PQ34EPhuVO9E4K/AeRWtFKLT6Zqy3I3i5zZKnsVeDdzinLulZCVmdiLQ2cws5ZfTDVhWxjZXA93KOYFXcpubgK+Ag51za8qoa10Zn0EEtG8PAMY657ZHn2MK8FZlK4U4pzPWzLqYWXvgeuCpCso+AIwxs0HmtTSzM8ysNTALP9f7lWbW1MyGA0eXU8+7+C/0tqiOZmY2JMrbAHSJjqNxzhVF251kZp0AzKyzmZ0alZ8GjDSzg8ysBTC+Oh/ezDKjE4xNgIyoLU2rU4ekrUa9bwNzgFFm1jw6OX0pPvKpUIhO5wngVeAzfM89obyCzrn3gJ8Ak4E8YCn+OBXn3E5gePT+c2AE8Fw59RQCw/AnzlYBOVF5gNeBBcB6M9sUpY2LtjXbzLbij1MPiOqaDvwpWm9p9DNmZheY2YIKPv+P8P9t7gWOj5YfqKC81B+Nfd++BH8yOwdYA/QCLqqgvK+3+GFkzTKzFfj7BmbU2kZE6oD27d3XYO5IFpH6QZ2OiASVNo9BiEjjoEhHRIIKOnLgKRnnNuqw6rWip9NvEiLZY9qvq7dfK9IRkaDU6YhIUOp0RCQodToiEpQ6HREJSp2OiASlTkdEglKnIyJBqdMRkaDU6YhIUEEfg0hHW348GICjrpgHwOc7WwCQ962v4jJF+fmlVxSR3aJIR0SCUqcjIkE1ysMrN2RAvPzqrXcA0CajebEyp7f8ZvKNDq8kjW0a7U8R5B1SFKf1vzcPgMKFn1a6fpMunQE4YXqybLsm2wF49sBONdbOBEU6IhJUo4x0ipom+9qSEc7DW33P7nbuCtomkarIaNkyXt70lI9Qph8+EYBOmcm8aae2AeAv/XpWWmfO2d0BGNfhn3FaofNR07Mo0hGReq5RRjqrRheWSttW5M/bTDv7JACKvlwctE0iZdl52lEAbLnsSwDuO+yxOO/IrMTswD5aT0QnAPes8PtxNivKrXvpn44B4NGzJkcpyRjkopWJc5pbdrPl5VOkIyJBqdMRkaAa1eFV0YkDAfjrMfenpPppxY94czQAPRd8ELpZ0ghkHNYfANc0M5m2aiMAhbm5/n2zZnFe4REHADDhnvsAOCbbp2da02SZ6HDqZ2v9JfN/zjk8zus/ZSsAyQMuL3F5HWDqWfcCMKSZjz12FO2M8+a/cBAAnZlZtQ9YDYp0RCSoRhXprBjtZwo5OrtpqbzMRS1LpYnUlNHPvgTAsBZb47S5O/0FjXFLzwHg8PZr4rw/7ju1zHpSTxYPunEsAJ1eWgZAvw3vxnklI5wVE3yE88D598ZpJzQrXufB08fGef1uq/kIJ0GRjogE1aginYsPmVUqbdmubQDsN/Pr0M2RRuR7Lf1+VpgyLV/ikveMg56vdP078voC8OrYE+K0Dv+bHdVZxlx/Gb7uZb/3l9wX/PAuAJqQPKeUaEvinNCB132WzKu0RbtPkY6IBNUoIp2NPz0WgHEdSt8E9YOPLgGg/Yy5oZsljUivZ/zV0b17fx6n3dDPP3ZwVssdQPHzNQmXrvaRzZrj/ZWljF3vV2l7a57xV8sWD7oHSF71St3GQW+NBKDPz6OraJvWV6nuPaVIR0SCUqcjIkE1isOrLQP8E+OZ5vvYBTuTQ5G2vKdNnbRJGpe+V75TKu3ew78LwJfTXgXgB61yS5W5s8sMAI4ffTUA+z36cZxXuDW6/G4GwNI7BsV5CwfdHS0lTxwD/HTNkHi59+XrACjILb3d2qRIR0SCarCRTuZB/eLl509JnED295I/v3VgnJf98pyQzRKJFX2wCIC7JpwHQOsbH4nzzmjhL7E3tywA3rvO78MTRx8Ql3l86ikAfNmvAIDlZ02J8wpd8QjnkNkXANB97OZkmdwwJ45LUqQjIkE12Ehn+bl7x8sDsrOL5c3c3Cvl3dpALRIpW9vH/E2rE7deGKe9e5NPu7id/9mjiZ8a6Zr2yXGervlF8TGfUm88LIhu7+v/on+04cDrlvj0vLyabPpuUaQjIkGp0xGRoBrs4dWuvUrf3ZlX6O/83H5HlzitmQ6vJE00/0fyKfE5//AngucOuBSAxVf5R8IfPv6huMyQ7NL7eMLSXf7kcr8xvs7afJaquhTpiEhQDTbSmT/iTynv/H+JHy0727978d0y1hBJPxmb/Q2A7dr7yOWE5OCCxU4cQ/LmV4Crl50bLeXUZvN2iyIdEQmqwUU6O4b7W8GzrfRT41+P3xeADNYFbZPI7lr/na4AvHvEn4GyL4uvLPBPoPdukpw48g+9nwHg7NuuAqDXr6Lovqjuz+4o0hGRoBpMpJMYSb/NlasAaGrJ28Af3epvFGy6zh8f131fL1KxjNatAcj6/sZyywy472cAdJvgHyZd/1zy0Z95Rz0OwCc/8hHSsEdGAFC4aEnNN7aaFOmISFDqdEQkqAZzeGWt/BQyL/WbXipv0uKTAej06SdB2ySyu1z/HgDMOtzPXb6jyF8yH/DWqLhMz5ujiQaigdlbPpkcGyrzaB9PJG6IpSB9Tioo0hGRoBpMpFORL1b5/wCd6rgdIlX11T7+8ndiIPVN0ZS/PVPveS0x9UzuQIuXE+stKfADslv+TtKFIh0RCapRRDr97/JjwKbPUa1IxZq/Mg+Ai1cNBeDR7v8DYNPhyemvO311IAArbvB/xrOOmRjnZZovl+98XOHKmEq7rijSEZGg1OmISFAN5/AqOqm2riCam7xJq7psjcgecQX+EvmiBw4GYNtv/TQ1c8ffG5cpOSNo4pAK4IsiP83S+MuuACBr6Xu119hqUqQjIkE1mEincLOfI/oHY/2kZL2uX5TM/HxLXTRJZI+1f8jfAHj+Rd8D4IW+r8R5ifFzEhHPP3ckB9u5atplAPT816wg7awORToiElSDiXQSEqMCrn2xjhsiUoMKxvinzr/ZNfkYxOqR/rxP5hI/PU3vB1bGeT1z0i/CSVCkIyJBNbhIR6QhSoyD0zTlVGWvV4uXKQjYnj2hSEdEglKnIyJB1etOZ4Gbw1L3MQB5LpeZ7pVK1qgZM9wz7HDbgmxLGqeGvG83mHM67awjx3JapeXWuhWsYTlH2UkBWgWfug/IZR07ycfMPgFudc49GmTj0iCk6749y71KPtsxs0Qv1QyY7pwbVtF65kqMyVFXzKyJc65a58LM7GEgxzl3QzXWGQmMcs4dV70WFqvDAX2dc0urUPYm4EngU+Ao4BXgDOfczN3dvtQvDXXfLrGeAZ8B4yv7p1qrh1dmtsLMrjOzhWaWZ2ZTzaxZlDfUzHLMbJyZrQemRulnmtl8M9tiZjPN7LCU+gaa2Twz+9LMniIxdWdKfSnvu5rZc2aWa2abzWyymR0ITAEGm9k2M9sSlc02s4lmtsrMNpjZFDNrnlLXtWa2zszWmtkl1fkOnHPjnXOfOOeKnHPvAG8Cg3fn+5T0oX27lBOAvYFnKy3pnKu1F7AC+BjoCrQH3gYmRHlD8Vf5bgeygebAQGAjMAjIBC6K6sgGsoCVwFVAU+AcYFeJ+nKi5UzgA2AS0BL/CzwuyhsJvFWinZOAF6I2tgZeBH4X5Z0GbAAOiep6AnBAnyj/fODDKn4fzYF1wGm1+b3rVfsv7dulvo+HgIerVDbAL2ZMyvvTgWUpX+ROoFlK/r3AzSXqWAyciO9J1xIdEkZ5M8v5xQwGcoEmZbSp2C8GMGA70DslbTCwPOXLvC0lr1/qL6aa38cj+MMrq+66eqXXS/t2se22ALYCQ6tSPsSJ5NUpyyuB/VPe5zrn8lPedwcuMrMrUtKyonUcsMZFnzKlvrJ0BVa6qh1Hd8R/aXP9YSngf1mJ2fr2B1LnKC5vmxUysz/g/6OcVOIzSP2lfdsbDnwO/LcqhUNcMu+astwN36MnlPzjWw3c4pxrm/Jq4Zx7En9Y0tlSvr2ovrKsBrqZWVmdasltbgK+Ag5O2WYb51xiQJ51ZXyGaolOJn8H+LZzbmt115e01ej37chFwKNV/WcaotMZa2ZdzKw9cD3wVAVlHwDGmNkg81qa2Rlm1hqYhT9OvtLMmprZcODocup5F/+F3hbV0czMhkR5G4AuZpYF4JwrirY7ycw6AZhZZzM7NSo/DRhpZgeZWQtgfHU+vJldhz82Ptk5t7k660raa9T7dlRfF+Ak/KmDKgnR6TwBvIq/nLYMmFBeQefce8BPgMlAHrAUf5yKc24nPowbiQ/lRgDPlVNPITAM6AOsAnKi8gCvAwuA9Wa2KUobF21rtpltBWYAB0R1TQf+FK23NPoZM7MLzGxBBZ//Vvx/kKXRVYVtZvarCspL/dHY922AHwGznHPLKimXrLc2Ty+Y2Qr8fQMzam0jInVA+/buq9ePQYhI/aNOR0SCSpvHIESkcVCkIyJBBX3K/JSMcxt1WPVa0dNWeSmpb7RfV2+/VqQjIkGp0xGRoNTpiEhQ6nREJCh1OiISlDodEQlKnY6IBKVOR0SCUqcjIkGp0xGRoBrMZHsVyWzbBoBFtx4AQNN2X5dbtmCTn/mj/125cVrhks9qsXUijYsiHREJSp2OiATV4A6vdn37GwB8ffXncdrADmsAeHH/KVWu59fHDYiX53+zAwCFeXk10USRYnJ+dSwACy6/J06bsKk/AA+/OnSP6s7+3McVXW5Nn1msFemISFANJtJpst++AFw/5UEAhmQX7VF9N3eaHy8ffd5YAPa+b9Ye1SlSpmg0nl2uME4a18FPwjDuh5VNxlCxIvzfwY7LdgGwpKBpnHf9yEsByPjv+3u0jepSpCMiQdX7SKfo+IEAnDLlP0D1I5x7tvQE4Kdtl5dbZls0B+Leu9E+kcp0vcPP7Dv0xHPjtDcOfbpG6s6I4opWGdkADMxK5q09tjkAXao0GXDNUaQjIkGp0xGRoOr94VXmTRsBuKJt5XcNHzHnAgD2uyX5sTNWbQDgnjFnAPDxpZNLrXf+MB9/vnNnZwAKc3NLlRHZXe5rf4f8XmdviNO+13ZYsTKf/KKbX+hY+m76dm/4u+jzhubHaW3bbgdg9hFP1mhba4IiHREJqt5HOpN6JU64+d5+7k5/2fGH/7giLtP3r9sA2HfeIgBcUfLSZGIpv1u3crfxxEsnAtBj87s10WSRMhVt317mMkCfq9dWun6Hv6TUlbi59aniZd7OT14y736vvxxfSFiKdEQkqHof6Qyfeg0AN5zvu/Tf3zMCgD53Jm/7rspMaHt9GF1LPK10XmZ+NJdYUej/CSJV16Tz/vFy69tXlVkm3yUjncItX9R6m8qiSEdEgqr3kU63m3xE8+hN/g6+faneg20ZLVsCcNnofxRLT9w0CNBz6koACna7lSK176sD94uX/97j/mJ5OQVfAXDD7ZfHaR2om8d6FOmISFDqdEQkqHp/eLWnlvzmMADGtH0bgFUFOwC4492T4zL9cuaGb5hINW24LL/cvHfy/emHDg/U/UgJinREJKhGGeks+8PgeHnR+f6xh0LnL4s/usWPPNjvYkU3Uj8UnehHWnjmyD+npGYXK/PE+kHR0vowjaqAIh0RCapRRTqfX+IjnJfPmxinZdC8WJl5W/yxb8YhHeK0oo8/CdA6kd2z5go/KmCfptml8l7Y3g6AwgvT509dkY6IBKVOR0SCSp+Yq4Zl9u0VLy++0c/w+dFJdwKQbc1LlT/ho3OA5JgmRds1Zo6knyb77hMvL5/cEYC/fePBKKVpqfK/etqPIdVjdd1fKk9QpCMiQaVfpJORCUBmm73ipFWXHgjAjs6ln/J++3t/BKB1RvGPkkFy7JtsS+SV/3H/d+gzAHy1eGepvPu3HATAv4cdCkDB8pUVfgSR2rLqwt7x8geD746WSkc4Y1b7MaD6POjH4Umn5wYV6YhIUGkX6eT8n7+J6cOxqWMV/7uCNVqUmZppyf600FU+LU2ifHOySuX9rN1SADJe8vW88uMhcZ6bu2eToYlURd5If7vH3y7/Y0pq8X310a2d4+X1P/S3fKRjVK5IR0SCSptIZ+NYP4n8ry56qpKSVZMa3SyLxhKZ9sWRAPy8fXLK4OaWVap8eRIzTrx4+2FxWpOTyystsucy9/YRy6hxfrynfk1LR+IbCv3+PemR4XFa5+XVG1cqJEU6IhKUOh0RCSptDq+2HOov6v2g1e7dlLe1yI8lcuqHFwHQ5LHks1Mt1vvL4JlvzAPgX8N/FucVZlmxetaf7sse0zs5t/nNXV4EoEcTf9J66xPJE3btKXsAbJE9kdnOPzO17XF/68jFe60uVWZTdFh12j2/BKDCCNNgAAAB40lEQVTzbel7SJVKkY6IBJU2kc4j376/8kKRMxYnp1zNn+in3Wi63UdK7f77fpSzpNz1Wzz3Trl5rf/mf245qF+ctuQFHzVd/MnpAHR8a2Ocp0lppDasvdDfEDvnkLvLLTNi0Y+A+hPhJCjSEZGg0ibSGXvPTwHIP2JH6cxV/gHNPk9u8e8XLouzsnetqZX2FC78NF6+6/QzAWj9lZ+8vmB1Tq1sUxq3xHRIAM1P31Bmmbvz+sbLrcf42zzS6RGHqlCkIyJBqdMRkaDS5vBq/4mVnwyr/J7h2lH46bLKC4nsoa3PJsfK+d+h08osMyO3f7xcmIbPVVWFIh0RCSptIh2Rxm58nxfLzdvl/M0Zy//TI07rxtrablKtUKQjIkEp0hFJE1d/eF68/P6gR4vlfWPKzwHoNqF+3QhYFkU6IhKUIh2RNNF5eHIUyjM5slheV+p/hJOgSEdEglKnIyJBqdMRkaDU6YhIUOacq+s2iEgjokhHRIJSpyMiQanTEZGg1OmISFDqdEQkKHU6IhKUOh0RCUqdjogEpU5HRIJSpyMiQanTEZGg1OmISFDqdEQkKHU6IhKUOh0RCUqdjogEpU5HRIJSpyMiQanTEZGg1OmISFDqdEQkKHU6IhKUOh0RCer/A0ayc0lv6P3IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_model(lr_model,train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
